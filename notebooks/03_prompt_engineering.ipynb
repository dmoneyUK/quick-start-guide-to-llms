{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34e3585a-6171-4e87-869b-7304924544f5",
      "metadata": {
        "id": "34e3585a-6171-4e87-869b-7304924544f5"
      },
      "source": [
        "# First Steps with Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaaccb4d",
      "metadata": {
        "id": "eaaccb4d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "!pip install cohere\n",
        "import cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e99528-ae78-4fbd-85da-dcb401671fb2",
      "metadata": {
        "id": "b9e99528-ae78-4fbd-85da-dcb401671fb2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "co = cohere.Client(userdata.get('COHERE_API_KEY'))\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    api_key=userdata.get(\"OPENAI_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694bb77f",
      "metadata": {
        "id": "694bb77f"
      },
      "outputs": [],
      "source": [
        "def test_prompt_openai(prompt, suppress=False, model='gpt-3.5-turbo', **kwargs):\n",
        "    \" a simple function to take in a prompt and run it through a given model \"\n",
        "\n",
        "    chat_completion = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "        **kwargs\n",
        "    )\n",
        "    answer = chat_completion.choices[0].message.content\n",
        "    if not suppress:\n",
        "        print(f'PROMPT:\\n------\\n{prompt}\\n------\\nRESPONSE\\n------\\n{answer}')\n",
        "    else:\n",
        "        return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c35e826",
      "metadata": {
        "id": "3c35e826"
      },
      "outputs": [],
      "source": [
        "def test_prompt_cohere(prompt, suppress=False, model='command-a-03-2025', **kwargs):\n",
        "    response = co.chat(\n",
        "        message=prompt,\n",
        "        model=model,\n",
        "        **kwargs,\n",
        "      )\n",
        "    if not suppress:\n",
        "        print(f'PROMPT:\\n------\\n{prompt}\\n------\\nRESPONSE\\n------\\n{response.text}')\n",
        "    else:\n",
        "        return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb55d646",
      "metadata": {
        "id": "fb55d646"
      },
      "source": [
        "## Just ASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989b22d8",
      "metadata": {
        "id": "989b22d8"
      },
      "outputs": [],
      "source": [
        "test_prompt_openai('Translate to Turkish.\\n\\nWhere is the nearest restaurant?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5422fa7",
      "metadata": {
        "id": "a5422fa7"
      },
      "outputs": [],
      "source": [
        "test_prompt_cohere('Translate to Turkish.\\n\\nWhere is the nearest restaurant?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b315fe0",
      "metadata": {
        "id": "2b315fe0"
      },
      "outputs": [],
      "source": [
        "# depending on the capability of the model, you may need to coax it to structure the output better\n",
        "# Not the best Turkish..\n",
        "test_prompt_cohere('Translate to Turkish.\\n\\nEnglish: Where is the nearest restaurant?\\nTurkish:')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294d176c",
      "metadata": {
        "id": "294d176c"
      },
      "source": [
        "# Few-shot learning\n",
        "\n",
        "Using examples to \"teach\" GPT-3 what to do\n",
        "\n",
        "## The original GPT-3 paper was called:\n",
        "![gpt3_paper.png](https://github.com/dmoneyUK/quick-start-guide-to-llms/blob/main/images/gpt3_paper.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dc5dc5",
      "metadata": {
        "id": "64dc5dc5"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    ('Review: This movie sucks\\nSubjective: Yes'),\n",
        "    ('Review: This tv show was about the ocean\\nSubjective: No'),\n",
        "    ('Review: This book had a lot of flaws\\nSubjective: Yes'),\n",
        "\n",
        "    ('Review: The book was about WWII\\nSubjective:'),\n",
        "]\n",
        "\n",
        "test_prompt_openai('\\n###\\n'.join(examples))  # ### is a common few-shot separator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd424801",
      "metadata": {
        "id": "fd424801"
      },
      "outputs": [],
      "source": [
        "# Cohere is getting this example right\n",
        "test_prompt_cohere('\\n###\\n'.join(examples))  # ### is a common few-shot separator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a5d1b2",
      "metadata": {
        "id": "f5a5d1b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015fe18e",
      "metadata": {
        "id": "015fe18e"
      },
      "outputs": [],
      "source": [
        "# Without the examples:\n",
        "test_prompt_openai('Review: The book was about WWII\\nSubjective:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a864d5",
      "metadata": {
        "id": "63a864d5"
      },
      "outputs": [],
      "source": [
        "# With a prompt\n",
        "test_prompt_openai('Tell me the subjectivity of this review.\\n\\nReview: The book was about WWII\\nSubjective:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a161cd1d",
      "metadata": {
        "id": "a161cd1d"
      },
      "outputs": [],
      "source": [
        "# Be more specific about the output\n",
        "test_prompt_openai('Tell me the subjectivity of this review with either \"Yes\" or \"No\".\\n\\nReview: The book was about WWII\\nSubjective:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd71cafb",
      "metadata": {
        "id": "bd71cafb"
      },
      "outputs": [],
      "source": [
        "# A different review\n",
        "test_prompt_openai('Tell me the subjectivity of this review with either \"Yes\" or \"No\".\\n\\nReview: The fight scenes were the best part!\\nSubjective:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8c8cfa",
      "metadata": {
        "id": "ba8c8cfa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c1c74b",
      "metadata": {
        "id": "29c1c74b"
      },
      "outputs": [],
      "source": [
        "# Be more specific about the output\n",
        "test_prompt_openai('Tell me the subjectivity of this review with either \"Yes\" or \"No\". Also as a JSON.\\n\\nReview: The book was about WWII\\nSubjective:')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642e06f4",
      "metadata": {
        "id": "642e06f4"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    ('Review: This movie sucks\\nSubjective: {\"answer\": true}'),\n",
        "    ('Review: This tv show was about the ocean\\nSubjective: {\"answer\": false}'),\n",
        "    ('Review: This book had a lot of flaws\\nSubjective: {\"answer\": true}'),\n",
        "\n",
        "    ('Review: The book was about WWII\\nSubjective:'),\n",
        "]\n",
        "\n",
        "test_prompt_openai('\\n###\\n'.join(examples))  # ### is a common few-shot separator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dc1f76",
      "metadata": {
        "id": "17dc1f76"
      },
      "source": [
        "# Personas / Style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5e593f",
      "metadata": {
        "id": "fc5e593f"
      },
      "outputs": [],
      "source": [
        "# It only takes a few words to pretty drastically change the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d438f619",
      "metadata": {
        "id": "d438f619"
      },
      "outputs": [],
      "source": [
        "style = 'rude'\n",
        "test_prompt_openai(f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185eba56",
      "metadata": {
        "id": "185eba56"
      },
      "outputs": [],
      "source": [
        "style = 'friendly'\n",
        "test_prompt_openai(f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b69af8",
      "metadata": {
        "id": "c3b69af8"
      },
      "outputs": [],
      "source": [
        "style = 'yoda'\n",
        "test_prompt_openai(f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdb366ee",
      "metadata": {
        "id": "bdb366ee"
      },
      "source": [
        "# What a good time to talk about output validation and bias!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed0eca2",
      "metadata": {
        "id": "3ed0eca2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495ae6c5",
      "metadata": {
        "id": "495ae6c5"
      },
      "outputs": [],
      "source": [
        "sequence_to_classify = \"All of this is your fault for being Turkish. You shouldn't be allowed to have an account on this website.\"\n",
        "\n",
        "candidate_labels = ['racist', 'sexist', 'rude']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels, multi_label=True)  # Assuming there can be multiple answers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a405c20",
      "metadata": {
        "id": "6a405c20"
      },
      "outputs": [],
      "source": [
        "# then the \"rude\" AI wasn't that bad\n",
        "classifier(\n",
        "    'Do you have your login information? Because if not, then there is nothing I can do for you.',\n",
        "    candidate_labels, multi_label=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2d2554",
      "metadata": {
        "id": "fc2d2554"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3969a7",
      "metadata": {
        "id": "ac3969a7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd993c1",
      "metadata": {
        "id": "ccd993c1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "style = 'friendly'\n",
        "responses = []\n",
        "for _ in tqdm(range(10)):\n",
        "    responses.append(test_prompt_openai(\n",
        "        f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:',\n",
        "        temperature=0,  # technically (mathematically) we cannot set temp to 0 so OpenAI is doing something under the hood here\n",
        "        suppress=True\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea44da0c",
      "metadata": {
        "id": "ea44da0c"
      },
      "outputs": [],
      "source": [
        "# only 1 unique response\n",
        "responses, len(set(responses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a92353",
      "metadata": {
        "id": "33a92353"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "style = 'friendly'\n",
        "responses = []\n",
        "for _ in tqdm(range(10)):\n",
        "    responses.append(test_prompt_openai(\n",
        "        f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:',\n",
        "        temperature=1,\n",
        "        suppress=True\n",
        "    ))\n",
        "# all different\n",
        "responses, len(set(responses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af695128-2847-41ae-8611-bd1fe02ee6db",
      "metadata": {
        "id": "af695128-2847-41ae-8611-bd1fe02ee6db"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "style = 'friendly'\n",
        "responses = []\n",
        "for _ in tqdm(range(10)):\n",
        "    responses.append(test_prompt_openai(\n",
        "        f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:',\n",
        "        temperature=2,\n",
        "        suppress=True,\n",
        "        max_tokens=50\n",
        "    ))\n",
        "# all different and horrible responses!\n",
        "responses, len(set(responses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e307b9f4-4beb-4a74-87e7-95df4680b14d",
      "metadata": {
        "id": "e307b9f4-4beb-4a74-87e7-95df4680b14d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3ad648-d453-4b26-ae2f-17530d1696d7",
      "metadata": {
        "id": "db3ad648-d453-4b26-ae2f-17530d1696d7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "style = 'friendly'\n",
        "responses = []\n",
        "for _ in tqdm(range(10)):\n",
        "    responses.append(test_prompt_openai(\n",
        "        f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:',\n",
        "        temperature=.1,\n",
        "        suppress=True\n",
        "    ))\n",
        "# all different and horrible responses!\n",
        "responses, len(set(responses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "521bda47",
      "metadata": {
        "id": "521bda47"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "style = 'friendly'\n",
        "responses = []\n",
        "for _ in tqdm(range(10)):\n",
        "    responses.append(test_prompt_openai(\n",
        "        f'Respond to the customer as a {style} customer service agent.\\n\\nCustomer: Hey! I cannot seem to get into my account. Can you help?\\nAgent:',\n",
        "        temperature=1,\n",
        "        top_p=.1,\n",
        "\n",
        "        suppress=True\n",
        "    ))\n",
        "# restricting top p allows fewer tokens to be considered, making the model more deterministic\n",
        "responses, len(set(responses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1082e662",
      "metadata": {
        "id": "1082e662"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}