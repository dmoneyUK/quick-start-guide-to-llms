{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmoneyUK/quick-start-guide-to-llms/blob/main/notebooks/02_semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b088054-daa2-4dbe-a71c-3a3dd58ab3b5",
      "metadata": {
        "id": "9b088054-daa2-4dbe-a71c-3a3dd58ab3b5"
      },
      "source": [
        "# Part 1: Setting up a basic semantic search system"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "722572bc",
      "metadata": {
        "id": "722572bc"
      },
      "source": [
        "A big thank you to [David on Github](https://github.com/gypsydave5) for finding a bug in my analysis code and bringing it to my attention. The bug was resolved!\n",
        "\n",
        "Some numbers might be different from what is reported in the book/video course but the overall gist is the same: re-ranking helps our semantic search and fine-tuning the re-ranking cross encoder yielded even better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aGixSoAgIzLo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGixSoAgIzLo",
        "outputId": "e3453bb4-ffdc-4a8b-851a-3780346b8ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (8.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.11.12)\n",
            "Requirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.5)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.0.1)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.1.0,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install pinecone openai sentence-transformers tiktoken datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c12182ab",
      "metadata": {
        "id": "c12182ab"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from datetime import datetime, timezone\n",
        "import hashlib\n",
        "import re\n",
        "import os\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "import logging\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f0289c54",
      "metadata": {
        "id": "f0289c54"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Get API keys from Colab secrets\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "pinecone_key = os.environ.get('PINECONE_API_KEY')\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "INDEX_NAME = 'semantic-search-test'\n",
        "NAMESPACE = 'default'\n",
        "ENGINE = 'text-embedding-3-large'  # has vector size 3072\n",
        "\n",
        "pc = Pinecone(\n",
        "    api_key=pinecone_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3cf993a3-6d51-49f4-8968-60f654d6202d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cf993a3-6d51-49f4-8968-60f654d6202d",
        "outputId": "fa19142e-3a42-4610-d804-0a8c402ab9e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# helper functions to get lists of embeddings from the OpenAI API\n",
        "def get_embeddings(texts, engine=ENGINE):\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=engine\n",
        "    )\n",
        "\n",
        "    return [d.embedding for d in list(response.data)]\n",
        "\n",
        "def get_embedding(text, engine=ENGINE):\n",
        "    return get_embeddings([text], engine)[0]\n",
        "\n",
        "len(get_embedding('hi')), len(get_embeddings(['hi', 'hello']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea70672a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea70672a",
        "outputId": "12054adb-10a6-46fe-8a06-3eb5c513ff17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pinecone.db_data.index.Index at 0x7abc4f737290>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    print(f'Creating index {INDEX_NAME}')\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,  # The name of the index\n",
        "        dimension=3072,  # The dimensionality of the vectors for our OpenAI embedder\n",
        "        metric='cosine',  # The similarity metric to use when searching the index\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Store the index as a variable\n",
        "index = pc.Index(name=INDEX_NAME)\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7f2fdfe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7f2fdfe7",
        "outputId": "b2bf01f2-1860-430d-8a6d-4f276adb9d34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ae76cc4dfd345ecaeea9b8ba0d5c3437'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def my_hash(s):\n",
        "    # Return the MD5 hash of the input string as a hexadecimal string\n",
        "    return hashlib.md5(s.encode()).hexdigest()\n",
        "\n",
        "my_hash('I love to hash it')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ecd86f51",
      "metadata": {
        "id": "ecd86f51"
      },
      "outputs": [],
      "source": [
        "def prepare_for_pinecone(texts, engine=ENGINE):\n",
        "    # Get the current UTC date and time\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    # Generate vector embeddings for each string in the input list, using the specified engine\n",
        "    embeddings = get_embeddings(texts, engine=engine)\n",
        "\n",
        "    # Create tuples of (hash, embedding, metadata) for each input string and its corresponding vector embedding\n",
        "    # The my_hash() function is used to generate a unique hash for each string, and the datetime.utcnow() function is used to generate the current UTC date and time\n",
        "    return [\n",
        "        (\n",
        "            my_hash(text),  # A unique ID for each string, generated using the my_hash() function\n",
        "            embedding,  # The vector embedding of the string\n",
        "            dict(text=text, date_uploaded=now)  # A dictionary of metadata, including the original text and the current UTC date and time\n",
        "        )\n",
        "        for text, embedding in zip(texts, embeddings)  # Iterate over each input string and its corresponding vector embedding\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4c40d99a",
      "metadata": {
        "id": "4c40d99a"
      },
      "outputs": [],
      "source": [
        "texts = ['hi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e1b73f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e1b73f3",
        "outputId": "213a3687-e57f-4fbd-e5e0-a9cd98ce4319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID:   49f68a5c8493ec2c0bf489821c21fc3b \n",
            "LEN:  3072 \n",
            "META: {'text': 'hi', 'date_uploaded': '2026-01-11T23:28:37.883473+00:00'}\n"
          ]
        }
      ],
      "source": [
        "_id, embedding, metadata = prepare_for_pinecone(texts)[0]\n",
        "\n",
        "print('ID:  ',_id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bf47aabd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf47aabd",
        "outputId": "58f2ef94-0c77-426c-8516-5fc28bbaad74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def upload_texts_to_pinecone(texts, namespace=NAMESPACE, batch_size=None, show_progress_bar=False):\n",
        "    # Call the prepare_for_pinecone function to prepare the input texts for indexing\n",
        "    total_upserted = 0\n",
        "    if not batch_size:\n",
        "        batch_size = len(texts)\n",
        "\n",
        "    _range = range(0, len(texts), batch_size)\n",
        "    for i in tqdm(_range) if show_progress_bar else _range:\n",
        "        batch = texts[i: i + batch_size]\n",
        "        prepared_texts = prepare_for_pinecone(batch)\n",
        "\n",
        "        # Use the upsert() method of the index object to upload the prepared texts to Pinecone\n",
        "        total_upserted += index.upsert(\n",
        "            vectors=prepared_texts,\n",
        "            namespace=namespace\n",
        "        )['upserted_count']\n",
        "\n",
        "\n",
        "    return total_upserted\n",
        "\n",
        "# Call the upload_texts_to_pinecone() function with the input texts\n",
        "upload_texts_to_pinecone(texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "V0XI6RAom-Ln",
      "metadata": {
        "id": "V0XI6RAom-Ln"
      },
      "outputs": [],
      "source": [
        "def query_from_pinecone(query, top_k=3, include_metadata=True):\n",
        "    # get embedding from THE SAME embedder as the documents\n",
        "    query_embedding = get_embedding(query, engine=ENGINE)\n",
        "\n",
        "    return index.query(\n",
        "      vector=query_embedding,\n",
        "      top_k=top_k,\n",
        "      namespace=NAMESPACE,\n",
        "      include_metadata=include_metadata   # gets the metadata (dates, text, etc)\n",
        "    ).get('matches')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "84a0871f",
      "metadata": {
        "id": "84a0871f"
      },
      "outputs": [],
      "source": [
        "def delete_texts_from_pinecone(texts, namespace=NAMESPACE):\n",
        "    # Compute the hash (id) for each text\n",
        "    hashes = [hashlib.md5(text.encode()).hexdigest() for text in texts]\n",
        "\n",
        "    # The ids parameter is used to specify the list of IDs (hashes) to delete\n",
        "    return index.delete(ids=hashes, namespace=namespace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a5172f-a0c6-4692-ab77-83321e141679",
      "metadata": {
        "id": "a6a5172f-a0c6-4692-ab77-83321e141679"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4523cab6-0bc3-4791-9c73-7bd7d7e5858b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "67f518ea99724e29bacb31ff29ea23aa",
            "1d77ecd55d054b209ec715fb94cc4142",
            "7cc885dd3b72431a876d263942c9cd16",
            "a0b1c755d3f248459d1d808076e96ce1",
            "0bc76d825af1476ebd95099c6af29ac8",
            "17f78dfb96ec4236ada67377bfabbf47",
            "6f580c2f052a4a0bbe51669fd68fe695",
            "75ac65b1ef9041adbb0a67d9a74be11a",
            "b77e974d17904dd195296c37a68fb981",
            "86772e237d1144908b13a2228e698766",
            "1b68e7d81fe3419db37fd893c591868a",
            "1d467399de30455fa2881af3ccf3b387",
            "e98900ad7b5147db89799b2a20a4fc8d",
            "9490c0ed312b4c39a091b9fa988f4c44",
            "55ba747aed524694a03ac5c15859fbc7",
            "11184fe783a447e69788b3f299115a94",
            "5a724baf57234cdfaefbd3b1383c4557",
            "5acb639604b84a97b960b8f8d1b246ff",
            "759ed7c79a204ccfa6d73b7db0f28dad",
            "ca7214e81bb94775b234f102e9dd69a9",
            "8f4c5d83e2664ed6a31bfbabda3b2462",
            "32df7792910648bda92538ee8e393547",
            "1ec0d3b8f8a34c82953e72994a47af2d",
            "fe9fc03757ec48c890a1a562147845bf",
            "1e131e26f3be45e8a20bbd75a66f4e85",
            "1835a7004f974fa289aab38bd1f27ed0",
            "314c2d24b6274dc3a4a01e5de52f7c17",
            "7720344b3d45405fa316a00e2cea9f79",
            "65aeeffa926446a487fb349e05c81c1d",
            "6aa17fc893d24c9eb04ba89bb9a4d94f",
            "604be0d855464688b401eef33cbfa771",
            "208328220be443db9f3eea41c3e76f1d",
            "5627404847214d6ab72919580e0e8d4a",
            "c28049be26694c53aaf1383f1ab65bfb",
            "306a32976a30463386ccc3e3dba6118b",
            "5b5cbaae53344eb4a098fbc5285465d2",
            "fbc4eb8eb8b44414967da9616284a255",
            "2cd32f7ad5134a12954063507d3f06ca",
            "6ebc6f1e27084c62acf7315f72dc421d",
            "9c78e4e1c42f4635a1a0d73ef39e2e2a",
            "e3cb376c2653411e8b3b1f0b0a6ff3a5",
            "db068be496454d5ea3961cc0fc92408f",
            "4d947dd13c9b4f6cae9f7eff7514ea8a",
            "88a85022846440b098d17f346b1147da",
            "598134a50d7844a5a13eb70d36f7d948",
            "97c18bb9eb304f39ba3dc7177c4fb743",
            "66b1c2b452394389ab0c62e937851c18",
            "3b1f1698477542b98898c91d5930230e",
            "95d2478375ed474cba9b8b95c2826baf",
            "4bd9467c46514f79bd097b8b4d8999d8",
            "a5166614e17545689e00f85d4270e5fc",
            "93cdd2fe54d342ec9994495c56980388",
            "7d09602ba6204c07a49427a751d39ab4",
            "ebeb99b71ffe4f539008370e90d0ac57",
            "c8fc80c8d8ff4fe68fce2f75daa2d913"
          ]
        },
        "id": "4523cab6-0bc3-4791-9c73-7bd7d7e5858b",
        "outputId": "063b157a-5e60-4746-8261-c8b35fdb8917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67f518ea99724e29bacb31ff29ea23aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MLQA.en.en/test-00000-of-00001.parquet:   0%|          | 0.00/7.49M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d467399de30455fa2881af3ccf3b387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MLQA.en.en/validation-00000-of-00001.par(…):   0%|          | 0.00/724k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ec0d3b8f8a34c82953e72994a47af2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/11590 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c28049be26694c53aaf1383f1ab65bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1148 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "598134a50d7844a5a13eb70d36f7d948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 1148\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 11590\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"xtreme\", \"MLQA.en.en\")\n",
        "\n",
        "# rename test -> train and val -> test (as we will use it in later in this chapter)\n",
        "dataset['train'] = dataset['test']\n",
        "dataset['test'] = dataset['validation']\n",
        "del dataset['validation']\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e622fbfa-2dde-4711-9c46-1390eb3430f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e622fbfa-2dde-4711-9c46-1390eb3430f9",
        "outputId": "8e4b9166-87b1-464a-97ab-06761e3f7fae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'id': 'a4968ca8a18de16aa3859be760e43dbd3af3fce9',\n",
              "  'title': 'Area 51',\n",
              "  'context': 'In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials). They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"',\n",
              "  'question': 'Who analyzed the biopsies?',\n",
              "  'answers': {'answer_start': [457],\n",
              "   'text': ['Rutgers University biochemists']}},\n",
              " {'id': 'f251ea56c4f1aa1df270137f7e6d89c0cc1b6ef4',\n",
              "  'title': 'Area 51',\n",
              "  'context': 'In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials). They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"',\n",
              "  'question': 'who represented robert frost and walter kasza in their suit?',\n",
              "  'answers': {'answer_start': [218],\n",
              "   'text': ['George Washington University law professor Jonathan Turley']}})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataset['train'][0], dataset['train'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0221343a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "0221343a",
        "outputId": "c71ec2cb-d3c6-44a7-9a24-a0ba8f261396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 13/31 [00:24<00:33,  1.87s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2125466344.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_passages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpassages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_passages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mupload_texts_to_pinecone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2012589041.py\u001b[0m in \u001b[0;36mupload_texts_to_pinecone\u001b[0;34m(texts, namespace, batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Use the upsert() method of the index object to upload the prepared texts to Pinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         total_upserted += index.upsert(\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/utils/error_handling.py\u001b[0m in \u001b[0;36minner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Lazy import of urllib3 exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/db_data/index.py\u001b[0m in \u001b[0;36mupsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m             \u001b[0;31m# If async_req=True, result is an ApplyResult[OpenAPIUpsertResponse]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# We need to wrap it to convert to our dataclass when .get() is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/db_data/index.py\u001b[0m in \u001b[0;36m_upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     ) -> UpsertResponse | ApplyResult:\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# Convert OpenAPI UpsertResponse to dataclass UpsertResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         result = self._vector_api.upsert_vectors(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mIndexRequestFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_openapi_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/endpoint.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/core/openapi/db_data/api/vector_operations_api.py\u001b[0m in \u001b[0;36m__upsert_vectors\u001b[0;34m(self, upsert_request, x_pinecone_api_version, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsert_request\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsert_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             return cast(\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0mUpsertResponse\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mApplyResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUpsertResponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             )\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/endpoint.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mHeaderUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"endpoint_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"http_method\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             return self.__call_api(\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mresource_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             return self.rest_client.POST(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/rest_utils.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     ):\n\u001b[0;32m--> 146\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pinecone/openapi_support/rest_urllib3.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    191\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# content_type == \"application/json\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                             \u001b[0mrequest_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                     r = self.pool_manager.request(\n\u001b[0m\u001b[1;32m    194\u001b[0m                         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/_request_methods.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    141\u001b[0m             )\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             return self.request_encode_body(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/_request_methods.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "unique_passages = list(set(dataset['test']['context']))\n",
        "for idx in tqdm(range(0, len(unique_passages), 32)):\n",
        "    passages = unique_passages[idx:idx + 32]\n",
        "    upload_texts_to_pinecone(passages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "796a7c80-7149-430e-b22c-9926c0d1daee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "796a7c80-7149-430e-b22c-9926c0d1daee",
        "outputId": "e77a7b0d-8f23-4570-d641-0eecb49c8f31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "978"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(unique_passages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "33yf7QrWtwt-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33yf7QrWtwt-",
        "outputId": "f66a9bda-859a-4367-a4d3-10be22325ef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
              "                                    'content-length': '182',\n",
              "                                    'content-type': 'application/json',\n",
              "                                    'date': 'Sun, 11 Jan 2026 23:29:38 GMT',\n",
              "                                    'grpc-status': '0',\n",
              "                                    'server': 'envoy',\n",
              "                                    'x-envoy-upstream-service-time': '73',\n",
              "                                    'x-pinecone-request-id': '6341919088014888061',\n",
              "                                    'x-pinecone-request-latency-ms': '72',\n",
              "                                    'x-pinecone-response-duration-ms': '74'}},\n",
              " 'dimension': 3072,\n",
              " 'index_fullness': 0.0,\n",
              " 'memoryFullness': 0.0,\n",
              " 'metric': 'cosine',\n",
              " 'namespaces': {'default': {'vector_count': 980}},\n",
              " 'storageFullness': 0.0,\n",
              " 'total_vector_count': 980,\n",
              " 'vector_type': 'dense'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "432b021b-2cdb-4d73-a2c6-f2e0d1eb5ffc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432b021b-2cdb-4d73-a2c6-f2e0d1eb5ffc",
        "outputId": "42341053-ff76-4ae8-cd1d-529ed6dbce5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '569666f4dc3983dab5624e989212c1d9d0cd1798',\n",
              " 'title': 'Pappataci fever',\n",
              " 'context': 'Pappataci fever is prevalent in the subtropical zone of the Eastern Hemisphere between 20°N and 45°N, particularly in Southern Europe, North Africa, the Balkans, Eastern Mediterranean, Iraq, Iran, Pakistan, Afghanistan and India.The disease is transmitted by the bites of phlebotomine sandflies of the Genus Phlebotomus, in particular, Phlebotomus papatasi, Phlebotomus perniciosus and Phlebotomus perfiliewi. The sandfly becomes infected when biting an infected human in the period between 48 hours before the onset of fever and 24 hours after the end of the fever, and remains infected for its lifetime. Besides this horizontal virus transmission from man to sandfly, the virus can be transmitted in insects transovarially, from an infected female sandfly to its offspring.Pappataci fever is seldom recognised in endemic populations because it is mixed with other febrile illnesses of childhood, but it is more well-known among immigrants and military personnel from non-endemic regions.',\n",
              " 'question': 'Does an infection for Sandflies go away over time?',\n",
              " 'answers': {'answer_start': [571],\n",
              "  'text': ['remains infected for its lifetime']}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "dataset['test'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "36e13316-2295-4a72-8f2a-b459f0e7826a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36e13316-2295-4a72-8f2a-b459f0e7826a",
        "outputId": "6a1a74e2-55a9-47f8-f6fb-2da4e328e27a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '2f90090e21f19450887d5f3ff781e541',\n",
              "  'metadata': {'date_uploaded': '2026-01-11T23:29:26.995695+00:00',\n",
              "               'text': 'Pappataci fever is prevalent in the subtropical zone of '\n",
              "                       'the Eastern Hemisphere between 20°N and 45°N, '\n",
              "                       'particularly in Southern Europe, North Africa, the '\n",
              "                       'Balkans, Eastern Mediterranean, Iraq, Iran, Pakistan, '\n",
              "                       'Afghanistan and India.The disease is transmitted by the '\n",
              "                       'bites of phlebotomine sandflies of the Genus '\n",
              "                       'Phlebotomus, in particular, Phlebotomus papatasi, '\n",
              "                       'Phlebotomus perniciosus and Phlebotomus perfiliewi. The '\n",
              "                       'sandfly becomes infected when biting an infected human '\n",
              "                       'in the period between 48 hours before the onset of '\n",
              "                       'fever and 24 hours after the end of the fever, and '\n",
              "                       'remains infected for its lifetime. Besides this '\n",
              "                       'horizontal virus transmission from man to sandfly, the '\n",
              "                       'virus can be transmitted in insects transovarially, '\n",
              "                       'from an infected female sandfly to its '\n",
              "                       'offspring.Pappataci fever is seldom recognised in '\n",
              "                       'endemic populations because it is mixed with other '\n",
              "                       'febrile illnesses of childhood, but it is more '\n",
              "                       'well-known among immigrants and military personnel from '\n",
              "                       'non-endemic regions.'},\n",
              "  'score': 0.435842514,\n",
              "  'values': []},\n",
              " {'id': '00661b04eb84a4664717245513ea30cd',\n",
              "  'metadata': {'date_uploaded': '2026-01-11T23:13:43.594950+00:00',\n",
              "               'text': 'Paratyphoid fever, also known simply as paratyphoid, is '\n",
              "                       'a bacterial infection caused by one of the three types '\n",
              "                       'of Salmonella enterica. Symptoms usually begin 6–30 '\n",
              "                       'days after exposure and are the same as those of '\n",
              "                       'typhoid fever. Often, a gradual onset of a high fever '\n",
              "                       'occurs over several days. Weakness, loss of appetite, '\n",
              "                       'and headaches also commonly occur. Some people develop '\n",
              "                       'a skin rash with rose-colored spots. Without treatment, '\n",
              "                       'symptoms may last weeks or months. Other people may '\n",
              "                       'carry the bacteria without being affected; however, '\n",
              "                       'they are still able to spread the disease to others. '\n",
              "                       'Both typhoid and paratyphoid are of similar severity. '\n",
              "                       'Paratyphoid and typhoid fever are types of enteric '\n",
              "                       'fever.Paratyphoid is caused by the bacterium Salmonella '\n",
              "                       'enterica of the serotypes Paratyphi A, Paratyphi B, or '\n",
              "                       'Paratyphi C growing in the intestines and blood. They '\n",
              "                       'are usually spread by eating or drinking food or water '\n",
              "                       'contaminated with the feces of an infected person. They '\n",
              "                       'may occur when a person who prepares food is infected. '\n",
              "                       'Risk factors include poor sanitation as is found among '\n",
              "                       'poor crowded populations. Occasionally, they may be '\n",
              "                       'transmitted by sex. Humans are the only animals '\n",
              "                       'infected. Diagnosis may be based on symptoms and '\n",
              "                       'confirmed by either culturing the bacteria or detecting '\n",
              "                       'the bacterial DNA in the blood, stool, or bone marrow. '\n",
              "                       'Culturing the bacteria can be difficult. Bone-marrow '\n",
              "                       'testing is the most accurate. Symptoms are similar to '\n",
              "                       'that of many other infectious diseases. Typhus is an '\n",
              "                       'unrelated disease.While no vaccine is available '\n",
              "                       'specifically for paratyphoid, the typhoid vaccine may '\n",
              "                       'provide some benefit. Prevention includes drinking '\n",
              "                       'clean water, better sanitation, and better handwashing. '\n",
              "                       'Treatment of the disease is with antibiotics such as '\n",
              "                       'azithromycin. Resistance to a number of other '\n",
              "                       'previously effective antibiotics is common.Paratyphoid '\n",
              "                       'affects about six million people a year. It is most '\n",
              "                       'common in parts of Asia and rare in the developed '\n",
              "                       'world. Most cases are due to Paratyphi A rather than '\n",
              "                       'Paratyphi B or C. In 2015, paratyphoid fever resulted '\n",
              "                       'in about 29,200 deaths, down from 63,000 deaths in '\n",
              "                       '1990. The risk of death is between 10 and 15% without '\n",
              "                       'treatment, while with treatment, it may be less than '\n",
              "                       '1%.'},\n",
              "  'score': 0.325193375,\n",
              "  'values': []},\n",
              " {'id': '24d322a7ce10e9e2fa12fcf54f50c651',\n",
              "  'metadata': {'date_uploaded': '2026-01-11T23:14:20.080221+00:00',\n",
              "               'text': 'Although Aronson isolated this mycobacterium in 1926 '\n",
              "                       'from a fish, it was not until 1951 that it was found to '\n",
              "                       'be the cause of human disease by Linell and Norden. '\n",
              "                       'Large outbreaks of infection due to this atypical '\n",
              "                       'mycobacterium have been described in association with '\n",
              "                       'swimming. Infections related to swimming pools have now '\n",
              "                       'drastically fallen due to the improvements in the '\n",
              "                       'construction and maintenance of these facilities.The '\n",
              "                       'first case of M. marinum infection associated with a '\n",
              "                       \"fish-tank ('fish-tank granuloma') was reported in 1962 \"\n",
              "                       'by Swift and Cohen. M. marinum infection may be an '\n",
              "                       'occupational hazard for certain professions such as pet '\n",
              "                       'shop workers, but most infections occur in fish '\n",
              "                       'fanciers who keep an aquarium at home. Although '\n",
              "                       'infection may be caused by direct injury from the fish '\n",
              "                       'fins or bites, most are acquired during the handling of '\n",
              "                       'the aquariums such as cleaning or changing the water. '\n",
              "                       'Indirect infection has also been described related to a '\n",
              "                       'child’s bathing utensils that had been used to clean a '\n",
              "                       'fish tank. Due to an increased awareness of the disease '\n",
              "                       'and improved isolation methods, more and more cases are '\n",
              "                       'being recognized and reported worldwide.'},\n",
              "  'score': 0.301143646,\n",
              "  'values': []}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "query_from_pinecone('Does an infection for Sandflies go away over time?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5b92699e-2d92-4083-9508-ae47355c9c1a",
      "metadata": {
        "id": "5b92699e-2d92-4083-9508-ae47355c9c1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "206ab80e-f4b4-48d2-8aef-b522024f6658",
      "metadata": {
        "id": "206ab80e-f4b4-48d2-8aef-b522024f6658"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7e180a25-37e4-47a8-8ae8-a49f39c106ab",
      "metadata": {
        "id": "7e180a25-37e4-47a8-8ae8-a49f39c106ab"
      },
      "source": [
        "# Part 2: Making results more relevant with a cross-encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "074fab6f",
      "metadata": {
        "id": "074fab6f"
      },
      "outputs": [],
      "source": [
        "# if you didn't import before\n",
        "\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "import numpy as np\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "414fc2d5",
      "metadata": {
        "id": "414fc2d5"
      },
      "outputs": [],
      "source": [
        "from copy import copy\n",
        "\n",
        "def get_results_from_pinecone(query, top_k=3, re_rank_model=None, verbose=True, correct_hash=None):\n",
        "\n",
        "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
        "\n",
        "    if not results_from_pinecone:\n",
        "        return []\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Query:\", query)\n",
        "\n",
        "\n",
        "    final_results = []\n",
        "\n",
        "    retrieved_correct_position, reranked_correct_position = None, None\n",
        "    for idx, result_from_pinecone in enumerate(results_from_pinecone):\n",
        "        if correct_hash and result_from_pinecone['id'] == correct_hash:\n",
        "            retrieved_correct_position = idx\n",
        "\n",
        "    if re_rank_model is not None:\n",
        "        if verbose:\n",
        "            print('Document ID (Hash)\\t\\tRetrieval Score\\tCE Score\\tText')\n",
        "\n",
        "        sentence_combinations = [[query, result_from_pinecone['metadata']['text']] for result_from_pinecone in results_from_pinecone]\n",
        "\n",
        "        # Compute the similarity scores for these combinations\n",
        "        similarity_scores = re_rank_model.predict(sentence_combinations, activation_fct=nn.Sigmoid())\n",
        "\n",
        "        # Sort the scores in decreasing order\n",
        "        sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
        "        sim_scores_sort = list(reversed(np.sort(similarity_scores)))\n",
        "        top_re_rank_score = sim_scores_sort[0]\n",
        "\n",
        "        # Print the scores\n",
        "        # print(list(zip(sim_scores_argsort, sim_scores_sort)))\n",
        "        for idx, _ in enumerate(sim_scores_argsort):\n",
        "            result_from_pinecone = results_from_pinecone[_]\n",
        "            if correct_hash and retrieved_correct_position == _:\n",
        "                reranked_correct_position = idx\n",
        "            final_results.append({'score': similarity_scores[idx], 'id': result_from_pinecone['id'], 'metadata': result_from_pinecone['metadata']})\n",
        "            if verbose:\n",
        "                print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{similarity_scores[idx]:.6f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
        "        return {'final_results': final_results, 'retrieved_correct_position': retrieved_correct_position, 'reranked_correct_position': reranked_correct_position, 'results_from_pinecone': results_from_pinecone, 'top_re_rank_score': top_re_rank_score}\n",
        "\n",
        "    if verbose:\n",
        "        print('Document ID (Hash)\\t\\tRetrieval Score\\tText')\n",
        "    for result_from_pinecone in results_from_pinecone:\n",
        "        final_results.append(result_from_pinecone)\n",
        "        if verbose:\n",
        "            print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
        "\n",
        "    return {'final_results': final_results, 'retrieved_correct_position': retrieved_correct_position, 'reranked_correct_position': reranked_correct_position}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_GPhx4MMIVqU",
      "metadata": {
        "id": "_GPhx4MMIVqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b25a8a8f-e873-43e7-9f56-b57bdf328416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25a8a8f-e873-43e7-9f56-b57bdf328416",
        "outputId": "5694d813-c10b-4983-d621-cfabb3eab579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Pre-trained cross encoder\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1, device=device)\n",
        "\n",
        "q_to_hash = {data['question']: my_hash(data['context']) for data in dataset['test']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "vptFN0wPw0uS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vptFN0wPw0uS",
        "outputId": "a23eee42-488e-4492-ae3b-9bedf67a4bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1148"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "unique_inputs = list(set(dataset['test']['question']))\n",
        "len(unique_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "dc56237c-f9d6-4b3d-a8ac-31098cf4f904",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc56237c-f9d6-4b3d-a8ac-31098cf4f904",
        "outputId": "a991664c-bb9a-406f-e01d-dcd48a529c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In what area of science was the Kekulé's theory?\n",
            "In 1856 Kekulé became Privatdozent at the University of Heidelberg.  In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career.  Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles-Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms. For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Alexander Butlerov.Kekulé's idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their \"Verwandtschaftseinheiten\" (\"affinity units\", now called \"valences\" or \"bonds\"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography.  Such physical methods of structural determination had not yet been developed, so chemists of Kekulé's day had to rely almost entirely on so-called \"wet\" chemistry. Some chemists, notably Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof.   However, most chemists followed Kekulé's lead in pursuing and developing what some have called \"classical\" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).\n"
          ]
        }
      ],
      "source": [
        "query = unique_inputs[0]\n",
        "print(query)\n",
        "\n",
        "for t in dataset['test']:\n",
        "    if t['question'] == query:\n",
        "        print(t['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4b0da5ac-0345-45e2-9913-188590a31522",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b0da5ac-0345-45e2-9913-188590a31522",
        "outputId": "18d38476-6c18-4d32-c311-4abdf19095ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "query_result = get_results_from_pinecone(\n",
        "    query,\n",
        "    top_k=2, # grab 2 results\n",
        "    re_rank_model=cross_encoder,\n",
        "    correct_hash=q_to_hash[query],\n",
        "    verbose=False\n",
        "    )\n",
        "\n",
        "query_result['retrieved_correct_position'], query_result['reranked_correct_position']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dfbb3b3c-9baa-4298-abd8-0e7b75dd24ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfbb3b3c-9baa-4298-abd8-0e7b75dd24ec",
        "outputId": "273be484-e2da-4304-9822-353e2d55dbef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'final_results': [{'score': np.float32(0.9941754),\n",
              "   'id': 'f5956c92855814565b6f4668b5e8f593',\n",
              "   'metadata': {'date_uploaded': '2026-01-11T23:29:21.522516+00:00',\n",
              "    'text': 'In 1856 Kekulé became Privatdozent at the University of Heidelberg.  In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career.  Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles-Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms. For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Alexander Butlerov.Kekulé\\'s idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their \"Verwandtschaftseinheiten\" (\"affinity units\", now called \"valences\" or \"bonds\"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography.  Such physical methods of structural determination had not yet been developed, so chemists of Kekulé\\'s day had to rely almost entirely on so-called \"wet\" chemistry. Some chemists, notably Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof.   However, most chemists followed Kekulé\\'s lead in pursuing and developing what some have called \"classical\" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).'}},\n",
              "  {'score': np.float32(3.1530373e-05),\n",
              "   'id': 'af9145f48f94fa1a815e1568ffee0cf9',\n",
              "   'metadata': {'date_uploaded': '2026-01-11T23:13:46.954336+00:00',\n",
              "    'text': 'The history of chemistry represents a time span from ancient history to the present. By 1000 BC, civilizations used technologies that would eventually form the basis of the various branches of chemistry. Examples include extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass,'}}],\n",
              " 'retrieved_correct_position': 0,\n",
              " 'reranked_correct_position': 0,\n",
              " 'results_from_pinecone': [{'id': 'f5956c92855814565b6f4668b5e8f593',\n",
              "   'metadata': {'date_uploaded': '2026-01-11T23:29:21.522516+00:00',\n",
              "                'text': 'In 1856 Kekulé became Privatdozent at the University of '\n",
              "                        'Heidelberg.  In 1858 he was hired as full professor at '\n",
              "                        'the University of Ghent, then in 1867 he was called to '\n",
              "                        'Bonn, where he remained for the rest of his career.  '\n",
              "                        'Basing his ideas on those of predecessors such as '\n",
              "                        'Williamson, Edward Frankland, William Odling, Auguste '\n",
              "                        'Laurent, Charles-Adolphe Wurtz and others, Kekulé was '\n",
              "                        'the principal formulator of the theory of chemical '\n",
              "                        'structure (1857–58). This theory proceeds from the idea '\n",
              "                        'of atomic valence, especially the tetravalence of '\n",
              "                        'carbon (which Kekulé announced late in 1857) and the '\n",
              "                        'ability of carbon atoms to link to each other '\n",
              "                        '(announced in a paper published in May 1858), to the '\n",
              "                        'determination of the bonding order of all of the atoms '\n",
              "                        'in a molecule. Archibald Scott Couper independently '\n",
              "                        'arrived at the idea of self-linking of carbon atoms '\n",
              "                        '(his paper appeared in June 1858), and provided the '\n",
              "                        'first molecular formulas where lines symbolize bonds '\n",
              "                        'connecting the atoms. For organic chemists, the theory '\n",
              "                        'of structure provided dramatic new clarity of '\n",
              "                        'understanding, and a reliable guide to both analytic '\n",
              "                        'and especially synthetic work. As a consequence, the '\n",
              "                        'field of organic chemistry developed explosively from '\n",
              "                        'this point. Among those who were most active in '\n",
              "                        'pursuing early structural investigations were, in '\n",
              "                        'addition to Kekulé and Couper, Frankland, Wurtz, '\n",
              "                        'Alexander Crum Brown, Emil Erlenmeyer, and Alexander '\n",
              "                        \"Butlerov.Kekulé's idea of assigning certain atoms to \"\n",
              "                        'certain positions within the molecule, and '\n",
              "                        'schematically connecting them using what he called '\n",
              "                        'their \"Verwandtschaftseinheiten\" (\"affinity units\", now '\n",
              "                        'called \"valences\" or \"bonds\"), was based largely on '\n",
              "                        'evidence from chemical reactions, rather than on '\n",
              "                        'instrumental methods that could peer directly into the '\n",
              "                        'molecule, such as X-ray crystallography.  Such physical '\n",
              "                        'methods of structural determination had not yet been '\n",
              "                        \"developed, so chemists of Kekulé's day had to rely \"\n",
              "                        'almost entirely on so-called \"wet\" chemistry. Some '\n",
              "                        'chemists, notably Hermann Kolbe, heavily criticized the '\n",
              "                        'use of structural formulas that were offered, as he '\n",
              "                        'thought, without proof.   However, most chemists '\n",
              "                        \"followed Kekulé's lead in pursuing and developing what \"\n",
              "                        'some have called \"classical\" structure theory, which '\n",
              "                        'was modified after the discovery of electrons (1897) '\n",
              "                        'and the development of quantum mechanics (in the '\n",
              "                        '1920s).'},\n",
              "   'score': 0.708788,\n",
              "   'values': []},\n",
              "  {'id': 'af9145f48f94fa1a815e1568ffee0cf9',\n",
              "   'metadata': {'date_uploaded': '2026-01-11T23:13:46.954336+00:00',\n",
              "                'text': 'The history of chemistry represents a time span from '\n",
              "                        'ancient history to the present. By 1000 BC, '\n",
              "                        'civilizations used technologies that would eventually '\n",
              "                        'form the basis of the various branches of chemistry. '\n",
              "                        'Examples include extracting metals from ores, making '\n",
              "                        'pottery and glazes, fermenting beer and wine, '\n",
              "                        'extracting chemicals from plants for medicine and '\n",
              "                        'perfume, rendering fat into soap, making glass,'},\n",
              "   'score': 0.341424942,\n",
              "   'values': []}],\n",
              " 'top_re_rank_score': np.float32(0.9941754)}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "query_result  # the right context isn't there!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "caa66ac8-d69c-49a1-9f55-e9ef93379fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caa66ac8-d69c-49a1-9f55-e9ef93379fec",
        "outputId": "3d5b2b36-f3d5-45ea-ade5-9dcee34c3176"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "query_result = get_results_from_pinecone(\n",
        "    query,\n",
        "    top_k=10, # grab 10 results\n",
        "    re_rank_model=cross_encoder, correct_hash=q_to_hash[query],\n",
        "    verbose=False\n",
        "    )\n",
        "\n",
        "query_result['retrieved_correct_position'], query_result['reranked_correct_position']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uk1lhptdUfrL",
      "metadata": {
        "id": "uk1lhptdUfrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a63ec53e",
      "metadata": {
        "id": "a63ec53e"
      },
      "outputs": [],
      "source": [
        "test_sample = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "21a3a147",
      "metadata": {
        "id": "21a3a147"
      },
      "outputs": [],
      "source": [
        "TOP_K=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98413a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b98413a3",
        "outputId": "aee809e7-48e6-49f1-f789-9987c6794528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 100/1148 [00:41<08:24,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without re-ranking: 0.78\n",
            "Accuracy with re-ranking: 0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 200/1148 [01:22<06:33,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without re-ranking: 0.765\n",
            "Accuracy with re-ranking: 0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 300/1148 [02:01<05:07,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without re-ranking: 0.7666666666666667\n",
            "Accuracy with re-ranking: 0.8166666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 333/1148 [02:13<05:11,  2.61it/s]"
          ]
        }
      ],
      "source": [
        "logger.setLevel(logging.CRITICAL)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for question in tqdm(test_sample['question']):\n",
        "    r = get_results_from_pinecone(\n",
        "        question, top_k=TOP_K, re_rank_model=cross_encoder, correct_hash=q_to_hash[question],\n",
        "        verbose=False\n",
        "        )\n",
        "\n",
        "    r['retrieved_correct_position'], r['reranked_correct_position']\n",
        "    predictions.append(r)\n",
        "    if len(predictions) % 100 == 0:\n",
        "        retrieved_accuracy = sum([_['retrieved_correct_position'] == 0 for _ in predictions])/len(predictions)\n",
        "        re_ranked_accuracy = sum([_['reranked_correct_position'] == 0 for _ in predictions])/len(predictions)\n",
        "\n",
        "        print(f'Accuracy without re-ranking: {retrieved_accuracy}')\n",
        "        print(f'Accuracy with re-ranking: {re_ranked_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ff94e7-0b78-40ca-8cf0-42e345439e8b",
      "metadata": {
        "id": "a2ff94e7-0b78-40ca-8cf0-42e345439e8b"
      },
      "outputs": [],
      "source": [
        "retrieved_accuracy = sum([_['retrieved_correct_position'] == 0 for _ in predictions])/len(predictions)\n",
        "re_ranked_accuracy = sum([_['reranked_correct_position'] == 0 for _ in predictions])/len(predictions)\n",
        "\n",
        "print(f'Accuracy without re-ranking: {retrieved_accuracy}')\n",
        "print(f'Accuracy with re-ranking: {re_ranked_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fT4FuVcf9ONw",
      "metadata": {
        "id": "fT4FuVcf9ONw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6649afac-9434-440b-b332-de9149a7ebfa",
      "metadata": {
        "id": "6649afac-9434-440b-b332-de9149a7ebfa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831397d3-606a-4c7f-b77f-6ee85bd24f7e",
      "metadata": {
        "id": "831397d3-606a-4c7f-b77f-6ee85bd24f7e"
      },
      "outputs": [],
      "source": [
        "predictions_df[['retrieved_correct_position', 'reranked_correct_position']].mean()  # lower is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eyv-6pPIEy0r",
      "metadata": {
        "id": "eyv-6pPIEy0r"
      },
      "outputs": [],
      "source": [
        "# do recall @ 1, 3, 5, 10, etc\n",
        "X = [1, 3, 5, 10, 25, 50]\n",
        "OPENAI_RETRIEVAL = []\n",
        "OLD_CROSS_ENCODER = []\n",
        "\n",
        "for k in X:\n",
        "    embedding_only_recall = predictions_df[predictions_df['retrieved_correct_position'] < k].shape[0]\n",
        "    reranked_recall = predictions_df[predictions_df['reranked_correct_position'] < k].shape[0]\n",
        "    OPENAI_RETRIEVAL.append(embedding_only_recall / predictions_df.shape[0])\n",
        "    OLD_CROSS_ENCODER.append(reranked_recall / predictions_df.shape[0])\n",
        "    print(k, embedding_only_recall, reranked_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9aef05-e271-41e0-a8ce-88b6c81bed4c",
      "metadata": {
        "id": "bd9aef05-e271-41e0-a8ce-88b6c81bed4c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3f14809e",
      "metadata": {
        "id": "3f14809e"
      },
      "source": [
        "## OPEN SOURCE ALTERNATIVE TO EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed58d3a-bed5-4f70-a4d6-3d624ab98868",
      "metadata": {
        "id": "8ed58d3a-bed5-4f70-a4d6-3d624ab98868"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# load up our open source embedding model\n",
        "bi_encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "# bi_encoder = SentenceTransformer(\"sentence-transformers/msmarco-MiniLM-L-6-v3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be37c48b",
      "metadata": {
        "id": "be37c48b"
      },
      "outputs": [],
      "source": [
        "#Encode query and documents\n",
        "docs = dataset['test']['context']\n",
        "doc_emb = bi_encoder.encode(docs, batch_size=32, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ec2a2d-9ca6-4f5e-a0db-3be16c2363ff",
      "metadata": {
        "id": "b9ec2a2d-9ca6-4f5e-a0db-3be16c2363ff"
      },
      "outputs": [],
      "source": [
        "doc_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df00998-34d8-4f0b-9527-510d9515b233",
      "metadata": {
        "id": "4df00998-34d8-4f0b-9527-510d9515b233"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.util import semantic_search\n",
        "\n",
        "# Function to find most similar document\n",
        "def find_most_similar(embedder, text, embeddings, documents, k=3):\n",
        "    query_embedding = embedder.encode([text], show_progress_bar=False)\n",
        "    similarities = semantic_search(query_embedding, embeddings, top_k=k)\n",
        "    return [(documents[sim['corpus_id']], sim['score'], sim['corpus_id']) for sim in similarities[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0afee7",
      "metadata": {
        "id": "ae0afee7"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "\n",
        "query = sample(dataset['test']['question'], 1)[0]\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93280be8",
      "metadata": {
        "id": "93280be8"
      },
      "outputs": [],
      "source": [
        "def eval_ranking_open_source(embedder, doc_emb, query, top_k=3, re_rank_model=None):\n",
        "    ans = {'retrieved_correct_position': None}\n",
        "    correct_hash = q_to_hash[query]\n",
        "    results = find_most_similar(embedder, query, doc_emb, docs, k=top_k)\n",
        "    for idx, (passage, score, doc_idx) in enumerate(results):\n",
        "        if correct_hash == my_hash(passage):\n",
        "            ans['retrieved_correct_position'] =  idx\n",
        "    if re_rank_model is not None:\n",
        "        ans['reranked_correct_position'] = None\n",
        "        sentence_combinations = [(query, r[0]) for r in results]\n",
        "\n",
        "        # Compute the similarity scores for these combinations\n",
        "        similarity_scores = re_rank_model.predict(sentence_combinations, activation_fct=nn.Sigmoid())\n",
        "\n",
        "        # Sort the scores in decreasing order\n",
        "        sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
        "        for i, idx in enumerate(sim_scores_argsort):\n",
        "            r = results[idx]\n",
        "            if correct_hash and my_hash(r[0]) == correct_hash:\n",
        "                ans['reranked_correct_position'] = i\n",
        "\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f198cd",
      "metadata": {
        "id": "06f198cd"
      },
      "outputs": [],
      "source": [
        "eval_ranking_open_source(bi_encoder, doc_emb, query, top_k=TOP_K, re_rank_model=cross_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389511fa-38d3-4538-987d-1ff8a83ac85d",
      "metadata": {
        "id": "389511fa-38d3-4538-987d-1ff8a83ac85d"
      },
      "outputs": [],
      "source": [
        "logger.setLevel(logging.CRITICAL)\n",
        "os_predictions = []\n",
        "\n",
        "for i, question in tqdm(enumerate(test_sample), total=len(test_sample)):\n",
        "    os_predictions.append(eval_ranking_open_source(bi_encoder, doc_emb, question['question'], top_k=TOP_K, re_rank_model=cross_encoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935f031c-4965-4aed-aecd-0a2593f55115",
      "metadata": {
        "id": "935f031c-4965-4aed-aecd-0a2593f55115"
      },
      "outputs": [],
      "source": [
        "os_predictions_df = pd.DataFrame(os_predictions)\n",
        "os_predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88419a17-598b-4b3e-b314-e1c5ef3475eb",
      "metadata": {
        "id": "88419a17-598b-4b3e-b314-e1c5ef3475eb"
      },
      "outputs": [],
      "source": [
        "raw_accuracy = sum([p['retrieved_correct_position'] == 0 for p in os_predictions])/len(os_predictions)\n",
        "reranked_accuracy = sum([p['reranked_correct_position'] == 0 for p in os_predictions])/len(os_predictions)\n",
        "\n",
        "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
        "print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6fc44d-6af1-48b6-b859-01a1698c7dd9",
      "metadata": {
        "id": "cf6fc44d-6af1-48b6-b859-01a1698c7dd9"
      },
      "outputs": [],
      "source": [
        "# do recall @ 1, 3, 5, 10\n",
        "OPEN_SOURCE_RETRIEVAL = []\n",
        "OPEN_SOURCE_RETRIEVAL_PLUS_PRE_CE = []\n",
        "for k in X:\n",
        "    embedding_only_recall = os_predictions_df[os_predictions_df['retrieved_correct_position'] < k].shape[0]\n",
        "    reranked_recall = os_predictions_df[os_predictions_df['reranked_correct_position'] < k].shape[0]\n",
        "    print(k, embedding_only_recall, reranked_recall)\n",
        "    OPEN_SOURCE_RETRIEVAL.append(embedding_only_recall / os_predictions_df.shape[0])\n",
        "    OPEN_SOURCE_RETRIEVAL_PLUS_PRE_CE.append(reranked_recall / os_predictions_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f733061c-eb98-40cb-b116-602e1c0dcd3e",
      "metadata": {
        "id": "f733061c-eb98-40cb-b116-602e1c0dcd3e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X, OPENAI_RETRIEVAL, label='OAI Retrieval Only', marker='o')\n",
        "plt.plot(X, OLD_CROSS_ENCODER, label='OAI + Pretrained CE', marker='s')\n",
        "\n",
        "plt.plot(X, OPEN_SOURCE_RETRIEVAL, label='OS Retrieval Only', marker='*')\n",
        "plt.plot(X, OPEN_SOURCE_RETRIEVAL_PLUS_PRE_CE, label='OS + Pretrained CE', marker='^')\n",
        "\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Comparing embedding models + pre-trained vs fine-tuned CE (all retrieved 50 results then re-ranked)')\n",
        "plt.xlabel('Recall @')\n",
        "plt.ylabel('Performance')\n",
        "plt.xticks(X)\n",
        "plt.yticks([i/100 for i in range(70, 101, 5)])  # Adjusting y-ticks to start from 0.75\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097fe3bc-4fc1-4e69-bf60-6ab4f75da968",
      "metadata": {
        "id": "097fe3bc-4fc1-4e69-bf60-6ab4f75da968"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11e5dcd-7ad8-43d0-aa1b-2b94b3784253",
      "metadata": {
        "id": "f11e5dcd-7ad8-43d0-aa1b-2b94b3784253"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e3a30f-e913-43ad-9fa7-f712abfa59d0",
      "metadata": {
        "id": "06e3a30f-e913-43ad-9fa7-f712abfa59d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e6c207-7f75-4b04-8d32-541265902fa5",
      "metadata": {
        "id": "91e6c207-7f75-4b04-8d32-541265902fa5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec04ddb-5a7d-4506-a0ba-a3ddedf985df",
      "metadata": {
        "id": "9ec04ddb-5a7d-4506-a0ba-a3ddedf985df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c5cb27-018c-4299-a91f-6b39293c583e",
      "metadata": {
        "id": "30c5cb27-018c-4299-a91f-6b39293c583e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3200a66-9fc0-4f39-94e8-3456b85b6a96",
      "metadata": {
        "id": "c3200a66-9fc0-4f39-94e8-3456b85b6a96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ea30153c",
      "metadata": {
        "id": "ea30153c"
      },
      "source": [
        "## Advanced: Fine-tuning the re-ranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58979a1e-0fe1-488f-9805-56efd499278d",
      "metadata": {
        "id": "58979a1e-0fe1-488f-9805-56efd499278d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508edaf6",
      "metadata": {
        "id": "508edaf6"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bf1607",
      "metadata": {
        "id": "51bf1607"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import InputExample, losses, evaluation\n",
        "from torch.utils.data import DataLoader\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b58d2d0",
      "metadata": {
        "id": "6b58d2d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50fd5c19-894a-41e4-bf6f-d9e1197c053f",
      "metadata": {
        "id": "50fd5c19-894a-41e4-bf6f-d9e1197c053f"
      },
      "outputs": [],
      "source": [
        "unique_train_passages = list(set(dataset['train']['context']))\n",
        "len(unique_train_passages), len(dataset['train']['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eaad504-b944-4e36-987f-34126189c1a9",
      "metadata": {
        "id": "5eaad504-b944-4e36-987f-34126189c1a9"
      },
      "outputs": [],
      "source": [
        "len(unique_train_passages), doc_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361d5ef0-3fe3-4ed8-87c0-1cea3d9abcc2",
      "metadata": {
        "id": "361d5ef0-3fe3-4ed8-87c0-1cea3d9abcc2"
      },
      "outputs": [],
      "source": [
        "# use sentence_transformers.util.semantic_search\n",
        "train_doc_embed = bi_encoder.encode(unique_train_passages, batch_size=32, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d79fe9-f053-40e7-a2e6-2efd715b43f7",
      "metadata": {
        "id": "c7d79fe9-f053-40e7-a2e6-2efd715b43f7"
      },
      "outputs": [],
      "source": [
        "unique_train_passages = np.array(unique_train_passages)\n",
        "\n",
        "# Example usage\n",
        "print(unique_train_passages[0])\n",
        "\n",
        "find_most_similar(bi_encoder, unique_train_passages[0], train_doc_embed, unique_train_passages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "262e4ca4-0bfe-4243-9534-49370ed66b40",
      "metadata": {
        "id": "262e4ca4-0bfe-4243-9534-49370ed66b40"
      },
      "outputs": [],
      "source": [
        "# negative example mining\n",
        "train_samples = []\n",
        "\n",
        "for train_example in tqdm(dataset['train']):\n",
        "    # train_samples.append(\n",
        "    #         InputExample(\n",
        "    #             texts=[train_example['question'], train_example['context']], label=1\n",
        "    #         )\n",
        "    #     )\n",
        "    for i, (passage, score, corpus_idx) in enumerate(find_most_similar(bi_encoder, train_example['question'], train_doc_embed, unique_train_passages)):\n",
        "\n",
        "        train_samples.append(\n",
        "            InputExample(\n",
        "                texts=[train_example['question'], passage], label=int(passage == train_example['context'])\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "shuffle(train_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b281241b-54ed-4405-a101-f774efd2317d",
      "metadata": {
        "id": "b281241b-54ed-4405-a101-f774efd2317d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.Series([t.label for t in train_samples]).value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LOZkS9bSgwga",
      "metadata": {
        "id": "LOZkS9bSgwga"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7eaa40",
      "metadata": {
        "id": "8e7eaa40"
      },
      "outputs": [],
      "source": [
        "train_samples[2].__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2bc9d1",
      "metadata": {
        "id": "bc2bc9d1"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator, CEBinaryClassificationEvaluator\n",
        "import math\n",
        "import torch\n",
        "from random import sample\n",
        "\n",
        "logger.setLevel(logging.DEBUG)  # just to get some logs\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "model_save_path = './fine_tuned_ir_cross_encoder'\n",
        "\n",
        "train_dataloader = DataLoader(train_samples[:int(len(train_samples)*.8)], shuffle=True, batch_size=16)\n",
        "\n",
        "# An evaluator for training performance\n",
        "evaluator = CECorrelationEvaluator.from_input_examples(train_samples[int(len(train_samples)*.8):], name='test')\n",
        "\n",
        "# Rule of thumb for warmup steps\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
        "print(f\"Warmup-steps: {warmup_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4e8079-1335-4d53-944d-3ed0f6537781",
      "metadata": {
        "id": "ce4e8079-1335-4d53-944d-3ed0f6537781"
      },
      "outputs": [],
      "source": [
        "for t in train_samples:\n",
        "    if t.label == 1:\n",
        "        print('Example of label 1')\n",
        "        print(t.__dict__, cross_encoder.predict(t.texts, activation_fct=nn.Sigmoid()))\n",
        "        break\n",
        "for t in train_samples:\n",
        "    if t.label == 0:\n",
        "        print('Example of label 0')\n",
        "        print(t.__dict__, cross_encoder.predict(t.texts, activation_fct=nn.Sigmoid()))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f981bd03-bb31-492d-aabf-d5e6c7647704",
      "metadata": {
        "id": "f981bd03-bb31-492d-aabf-d5e6c7647704"
      },
      "outputs": [],
      "source": [
        "evaluator(cross_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de4dbc8",
      "metadata": {
        "id": "0de4dbc8"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "from sentence_transformers import InputExample, losses, evaluation\n",
        "\n",
        "# you may turn on debug for more logs here e.g. logger.setLevel(logging.DEBUG)\n",
        "cross_encoder.fit(\n",
        "    train_dataloader=train_dataloader,\n",
        "    loss_fct=nn.BCEWithLogitsLoss(),  # this is the default loss if num_labels is 1 otherwise CrossEntropyLoss\n",
        "    evaluator=evaluator,\n",
        "    epochs=num_epochs,\n",
        "    warmup_steps=warmup_steps,\n",
        "    output_path=model_save_path,\n",
        "    use_amp=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_a5R9sVBvHN",
      "metadata": {
        "id": "9_a5R9sVBvHN"
      },
      "outputs": [],
      "source": [
        "evaluator(cross_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f747537",
      "metadata": {
        "id": "2f747537"
      },
      "outputs": [],
      "source": [
        "finetuned = CrossEncoder(model_save_path)\n",
        "\n",
        "print(finetuned.predict(['hello', 'hi'], activation_fct=nn.Sigmoid()))\n",
        "print(finetuned.predict(['hello', 'hi'], activation_fct=nn.Identity()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cf736e",
      "metadata": {
        "id": "94cf736e"
      },
      "outputs": [],
      "source": [
        "logger.setLevel(logging.CRITICAL)\n",
        "\n",
        "ft_predictions = []\n",
        "\n",
        "for question in tqdm(test_sample['question']):\n",
        "    r = get_results_from_pinecone(\n",
        "        question, top_k=TOP_K, re_rank_model=finetuned, correct_hash=q_to_hash[question],\n",
        "        verbose=False\n",
        "        )\n",
        "\n",
        "    r['retrieved_correct_position'], r['reranked_correct_position']\n",
        "    ft_predictions.append(r)\n",
        "    if len(ft_predictions) % 100 == 0:\n",
        "        retrieved_accuracy = sum([_['retrieved_correct_position'] == 0 for _ in ft_predictions])/len(ft_predictions)\n",
        "        re_ranked_accuracy = sum([_['reranked_correct_position'] == 0 for _ in ft_predictions])/len(ft_predictions)\n",
        "\n",
        "        print(f'Accuracy without re-ranking: {retrieved_accuracy}')\n",
        "        print(f'Accuracy with re-ranking: {re_ranked_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07b782d-ef97-4c0a-be53-aefea5936676",
      "metadata": {
        "id": "a07b782d-ef97-4c0a-be53-aefea5936676"
      },
      "outputs": [],
      "source": [
        "retrieved_accuracy = sum([_['retrieved_correct_position'] == 0 for _ in ft_predictions])/len(ft_predictions)\n",
        "re_ranked_accuracy = sum([_['reranked_correct_position'] == 0 for _ in ft_predictions])/len(ft_predictions)\n",
        "\n",
        "print(f'Accuracy without re-ranking: {retrieved_accuracy}')\n",
        "print(f'Accuracy with re-ranking: {re_ranked_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb46e242",
      "metadata": {
        "id": "bb46e242"
      },
      "outputs": [],
      "source": [
        "# Re-ranking got slightly better after 1 epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfcd92e-31ad-4bf7-9e30-b6d260a06871",
      "metadata": {
        "id": "0cfcd92e-31ad-4bf7-9e30-b6d260a06871"
      },
      "outputs": [],
      "source": [
        "ft_predictions_df = pd.DataFrame(ft_predictions)\n",
        "ft_predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Sr2q5IN9LMz",
      "metadata": {
        "id": "9Sr2q5IN9LMz"
      },
      "outputs": [],
      "source": [
        "ft_predictions_df[['retrieved_correct_position', 'reranked_correct_position']].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b414c6",
      "metadata": {
        "id": "75b414c6"
      },
      "outputs": [],
      "source": [
        "ft_predictions_df[['retrieved_correct_position', 'reranked_correct_position']].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2535cbae",
      "metadata": {
        "id": "2535cbae"
      },
      "outputs": [],
      "source": [
        "# do recall @ 1, 3, 5, 10\n",
        "OPENAI_RETRIEVAL = []\n",
        "OPENAI_RETRIEVAL_PLUS_FT_CE = []\n",
        "for k in X:\n",
        "    embedding_only_recall = ft_predictions_df[ft_predictions_df['retrieved_correct_position'] < k].shape[0]\n",
        "    reranked_recall = ft_predictions_df[ft_predictions_df['reranked_correct_position'] < k].shape[0]\n",
        "    OPENAI_RETRIEVAL.append(embedding_only_recall / ft_predictions_df.shape[0])\n",
        "    OPENAI_RETRIEVAL_PLUS_FT_CE.append(reranked_recall / ft_predictions_df.shape[0])\n",
        "    print(k, embedding_only_recall, reranked_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e5e922-7667-4a02-b4fc-7acb9cc97c24",
      "metadata": {
        "id": "d9e5e922-7667-4a02-b4fc-7acb9cc97c24"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8faf0c1a",
      "metadata": {
        "id": "8faf0c1a"
      },
      "outputs": [],
      "source": [
        "logger.setLevel(logging.CRITICAL)\n",
        "os_predictions = []\n",
        "\n",
        "for i, question in tqdm(enumerate(test_sample), total=len(test_sample)):\n",
        "    os_predictions.append(eval_ranking_open_source(bi_encoder, doc_emb, question['question'], top_k=TOP_K, re_rank_model=finetuned))\n",
        "\n",
        "os_predictions_df = pd.DataFrame(os_predictions)\n",
        "os_predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eaeb9b4",
      "metadata": {
        "id": "6eaeb9b4"
      },
      "outputs": [],
      "source": [
        "raw_accuracy = sum([p['retrieved_correct_position'] == 0 for p in os_predictions])/len(os_predictions)\n",
        "reranked_accuracy = sum([p['reranked_correct_position'] == 0 for p in os_predictions])/len(os_predictions)\n",
        "\n",
        "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
        "print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T00iM9SyaUFI",
      "metadata": {
        "id": "T00iM9SyaUFI"
      },
      "outputs": [],
      "source": [
        "# do recall @ 1, 3, 5, 10\n",
        "OPEN_SOURCE_RETRIEVAL = []\n",
        "OPEN_SOURCE_RETRIEVAL_PLUS_FT_CE = []\n",
        "for k in X:\n",
        "    embedding_only_recall = os_predictions_df[os_predictions_df['retrieved_correct_position'] < k].shape[0]\n",
        "    reranked_recall = os_predictions_df[os_predictions_df['reranked_correct_position'] < k].shape[0]\n",
        "    print(k, embedding_only_recall, reranked_recall)\n",
        "    OPEN_SOURCE_RETRIEVAL.append(embedding_only_recall / os_predictions_df.shape[0])\n",
        "    OPEN_SOURCE_RETRIEVAL_PLUS_FT_CE.append(reranked_recall / os_predictions_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ub8HU8BZAW1",
      "metadata": {
        "id": "-ub8HU8BZAW1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X, OPENAI_RETRIEVAL, label='OAI Retrieval Only', marker='o')\n",
        "plt.plot(X, OPEN_SOURCE_RETRIEVAL, label='OS Retrieval Only', marker='*')\n",
        "plt.plot(X, OPEN_SOURCE_RETRIEVAL_PLUS_PRE_CE, label='OS + Pretrained CE', marker='^')\n",
        "\n",
        "plt.plot(X, OPEN_SOURCE_RETRIEVAL_PLUS_FT_CE, label='OS + Finetuned CE', marker='v')\n",
        "plt.plot(X, OLD_CROSS_ENCODER, label='OAI + Pretrained CE', marker='s')\n",
        "plt.plot(X, OPENAI_RETRIEVAL_PLUS_FT_CE, label='OAI + Finetuned CE', marker='d')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Comparing embedding models + pre-trained vs fine-tuned CE (all retrieved 50 results then re-ranked)')\n",
        "plt.xlabel('Recall @')\n",
        "plt.ylabel('Performance')\n",
        "plt.xticks(X)\n",
        "plt.yticks([i/100 for i in range(70, 101, 5)])  # Adjusting y-ticks to start from 0.75\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "plt.savefig('recall_at_k.png', dpi=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9oGQvj0xZAwo",
      "metadata": {
        "id": "9oGQvj0xZAwo"
      },
      "outputs": [],
      "source": [
        "# show results as a table\n",
        "\n",
        "results_df = pd.DataFrame({'RECALL @': [1, 3, 5, 10, 25, 50], 'OS_Retrieval_Only': OPEN_SOURCE_RETRIEVAL, 'OS_Retrieval_Plus_Finetuned_CE': OPEN_SOURCE_RETRIEVAL_PLUS_FT_CE   , 'OAI_Retrieval_Only': OPENAI_RETRIEVAL    , 'OAI_Retrieval_Plus_Pretrained_CE': OLD_CROSS_ENCODER, 'OAI_Retrieval_Plus_Finetuned_CE': OPENAI_RETRIEVAL_PLUS_FT_CE})\n",
        "results_df.sort_values(by='RECALL @')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OFno8WyIZDR6",
      "metadata": {
        "id": "OFno8WyIZDR6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "methods = [\n",
        "    \"OS_Retrieval_Only\",\n",
        "    \"OS_Retrieval_Plus_Finetuned_CE\",\n",
        "    \"OAI_Retrieval_Only\",\n",
        "    \"OAI_Retrieval_Plus_Pretrained_CE\",\n",
        "    \"OAI_Retrieval_Plus_Finetuned_CE\"\n",
        "]\n",
        "\n",
        "recalls = [0.501742, 0.642857, 0.753484, 0.833624, 0.890244]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(methods, recalls, color=\"skyblue\")\n",
        "\n",
        "# Add value labels on top of each bar\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        height + 0.005,\n",
        "        f\"{height:.3f}\",\n",
        "        ha=\"center\",\n",
        "        va=\"bottom\",\n",
        "        fontsize=9\n",
        "    )\n",
        "\n",
        "# Labeling and aesthetics\n",
        "plt.title(\"Recall@1 Across Different Methods\")\n",
        "plt.ylabel(\"Recall@1\")\n",
        "plt.xticks(rotation=25, ha=\"right\")  # Rotate x-axis labels if needed\n",
        "plt.ylim([0, 1])                    # Since recall values typically range [0,1]\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sIA-PtwdIEv3",
      "metadata": {
        "id": "sIA-PtwdIEv3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67f518ea99724e29bacb31ff29ea23aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d77ecd55d054b209ec715fb94cc4142",
              "IPY_MODEL_7cc885dd3b72431a876d263942c9cd16",
              "IPY_MODEL_a0b1c755d3f248459d1d808076e96ce1"
            ],
            "layout": "IPY_MODEL_0bc76d825af1476ebd95099c6af29ac8"
          }
        },
        "1d77ecd55d054b209ec715fb94cc4142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f78dfb96ec4236ada67377bfabbf47",
            "placeholder": "​",
            "style": "IPY_MODEL_6f580c2f052a4a0bbe51669fd68fe695",
            "value": "README.md: "
          }
        },
        "7cc885dd3b72431a876d263942c9cd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ac65b1ef9041adbb0a67d9a74be11a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b77e974d17904dd195296c37a68fb981",
            "value": 1
          }
        },
        "a0b1c755d3f248459d1d808076e96ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86772e237d1144908b13a2228e698766",
            "placeholder": "​",
            "style": "IPY_MODEL_1b68e7d81fe3419db37fd893c591868a",
            "value": " 131k/? [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "0bc76d825af1476ebd95099c6af29ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f78dfb96ec4236ada67377bfabbf47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f580c2f052a4a0bbe51669fd68fe695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75ac65b1ef9041adbb0a67d9a74be11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b77e974d17904dd195296c37a68fb981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86772e237d1144908b13a2228e698766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b68e7d81fe3419db37fd893c591868a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d467399de30455fa2881af3ccf3b387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e98900ad7b5147db89799b2a20a4fc8d",
              "IPY_MODEL_9490c0ed312b4c39a091b9fa988f4c44",
              "IPY_MODEL_55ba747aed524694a03ac5c15859fbc7"
            ],
            "layout": "IPY_MODEL_11184fe783a447e69788b3f299115a94"
          }
        },
        "e98900ad7b5147db89799b2a20a4fc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a724baf57234cdfaefbd3b1383c4557",
            "placeholder": "​",
            "style": "IPY_MODEL_5acb639604b84a97b960b8f8d1b246ff",
            "value": "MLQA.en.en/test-00000-of-00001.parquet: 100%"
          }
        },
        "9490c0ed312b4c39a091b9fa988f4c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_759ed7c79a204ccfa6d73b7db0f28dad",
            "max": 7493961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca7214e81bb94775b234f102e9dd69a9",
            "value": 7493961
          }
        },
        "55ba747aed524694a03ac5c15859fbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4c5d83e2664ed6a31bfbabda3b2462",
            "placeholder": "​",
            "style": "IPY_MODEL_32df7792910648bda92538ee8e393547",
            "value": " 7.49M/7.49M [00:00&lt;00:00, 70.4kB/s]"
          }
        },
        "11184fe783a447e69788b3f299115a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a724baf57234cdfaefbd3b1383c4557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5acb639604b84a97b960b8f8d1b246ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "759ed7c79a204ccfa6d73b7db0f28dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7214e81bb94775b234f102e9dd69a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f4c5d83e2664ed6a31bfbabda3b2462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32df7792910648bda92538ee8e393547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec0d3b8f8a34c82953e72994a47af2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe9fc03757ec48c890a1a562147845bf",
              "IPY_MODEL_1e131e26f3be45e8a20bbd75a66f4e85",
              "IPY_MODEL_1835a7004f974fa289aab38bd1f27ed0"
            ],
            "layout": "IPY_MODEL_314c2d24b6274dc3a4a01e5de52f7c17"
          }
        },
        "fe9fc03757ec48c890a1a562147845bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7720344b3d45405fa316a00e2cea9f79",
            "placeholder": "​",
            "style": "IPY_MODEL_65aeeffa926446a487fb349e05c81c1d",
            "value": "MLQA.en.en/validation-00000-of-00001.par(…): 100%"
          }
        },
        "1e131e26f3be45e8a20bbd75a66f4e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa17fc893d24c9eb04ba89bb9a4d94f",
            "max": 723558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_604be0d855464688b401eef33cbfa771",
            "value": 723558
          }
        },
        "1835a7004f974fa289aab38bd1f27ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_208328220be443db9f3eea41c3e76f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_5627404847214d6ab72919580e0e8d4a",
            "value": " 724k/724k [00:00&lt;00:00, 1.82MB/s]"
          }
        },
        "314c2d24b6274dc3a4a01e5de52f7c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7720344b3d45405fa316a00e2cea9f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65aeeffa926446a487fb349e05c81c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aa17fc893d24c9eb04ba89bb9a4d94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604be0d855464688b401eef33cbfa771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "208328220be443db9f3eea41c3e76f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5627404847214d6ab72919580e0e8d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28049be26694c53aaf1383f1ab65bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306a32976a30463386ccc3e3dba6118b",
              "IPY_MODEL_5b5cbaae53344eb4a098fbc5285465d2",
              "IPY_MODEL_fbc4eb8eb8b44414967da9616284a255"
            ],
            "layout": "IPY_MODEL_2cd32f7ad5134a12954063507d3f06ca"
          }
        },
        "306a32976a30463386ccc3e3dba6118b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebc6f1e27084c62acf7315f72dc421d",
            "placeholder": "​",
            "style": "IPY_MODEL_9c78e4e1c42f4635a1a0d73ef39e2e2a",
            "value": "Generating test split: 100%"
          }
        },
        "5b5cbaae53344eb4a098fbc5285465d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cb376c2653411e8b3b1f0b0a6ff3a5",
            "max": 11590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db068be496454d5ea3961cc0fc92408f",
            "value": 11590
          }
        },
        "fbc4eb8eb8b44414967da9616284a255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d947dd13c9b4f6cae9f7eff7514ea8a",
            "placeholder": "​",
            "style": "IPY_MODEL_88a85022846440b098d17f346b1147da",
            "value": " 11590/11590 [00:00&lt;00:00, 104961.75 examples/s]"
          }
        },
        "2cd32f7ad5134a12954063507d3f06ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebc6f1e27084c62acf7315f72dc421d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c78e4e1c42f4635a1a0d73ef39e2e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3cb376c2653411e8b3b1f0b0a6ff3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db068be496454d5ea3961cc0fc92408f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d947dd13c9b4f6cae9f7eff7514ea8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a85022846440b098d17f346b1147da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "598134a50d7844a5a13eb70d36f7d948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c18bb9eb304f39ba3dc7177c4fb743",
              "IPY_MODEL_66b1c2b452394389ab0c62e937851c18",
              "IPY_MODEL_3b1f1698477542b98898c91d5930230e"
            ],
            "layout": "IPY_MODEL_95d2478375ed474cba9b8b95c2826baf"
          }
        },
        "97c18bb9eb304f39ba3dc7177c4fb743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd9467c46514f79bd097b8b4d8999d8",
            "placeholder": "​",
            "style": "IPY_MODEL_a5166614e17545689e00f85d4270e5fc",
            "value": "Generating validation split: 100%"
          }
        },
        "66b1c2b452394389ab0c62e937851c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93cdd2fe54d342ec9994495c56980388",
            "max": 1148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d09602ba6204c07a49427a751d39ab4",
            "value": 1148
          }
        },
        "3b1f1698477542b98898c91d5930230e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebeb99b71ffe4f539008370e90d0ac57",
            "placeholder": "​",
            "style": "IPY_MODEL_c8fc80c8d8ff4fe68fce2f75daa2d913",
            "value": " 1148/1148 [00:00&lt;00:00, 34446.19 examples/s]"
          }
        },
        "95d2478375ed474cba9b8b95c2826baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd9467c46514f79bd097b8b4d8999d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5166614e17545689e00f85d4270e5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93cdd2fe54d342ec9994495c56980388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d09602ba6204c07a49427a751d39ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebeb99b71ffe4f539008370e90d0ac57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8fc80c8d8ff4fe68fce2f75daa2d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}