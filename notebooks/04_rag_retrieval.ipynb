{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "WaIDlfzUJXjN",
      "metadata": {
        "id": "WaIDlfzUJXjN"
      },
      "source": [
        "# Putting the R(etrieval) in RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aGixSoAgIzLo",
      "metadata": {
        "collapsed": true,
        "id": "aGixSoAgIzLo"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aLyppGK_hSi6",
      "metadata": {
        "id": "aLyppGK_hSi6"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0289c54",
      "metadata": {
        "id": "f0289c54"
      },
      "outputs": [],
      "source": [
        "# Retrieve the Pinecone API key from user data\n",
        "pinecone_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI client with the API key from user data\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "# Define constants for the Pinecone index, namespace, and engine\n",
        "INDEX_NAME = 'semantic-search-rag'  # The name of the Pinecone index\n",
        "NAMESPACE = 'default'  # The namespace to use within the index\n",
        "ENGINE = 'text-embedding-3-small'  # The embedding model to use (vector size 1,536)\n",
        "\n",
        "# Initialize the Pinecone client with the retrieved API key\n",
        "pc = Pinecone(\n",
        "    api_key=pinecone_key\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf993a3-6d51-49f4-8968-60f654d6202d",
      "metadata": {
        "id": "3cf993a3-6d51-49f4-8968-60f654d6202d"
      },
      "outputs": [],
      "source": [
        "# Function to get embeddings for a list of texts using the OpenAI API\n",
        "def get_embeddings(texts, engine=ENGINE):\n",
        "    # Create embeddings for the input texts using the specified engine\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=engine\n",
        "    )\n",
        "\n",
        "    # Extract and return the list of embeddings from the response\n",
        "    return [d.embedding for d in list(response.data)]\n",
        "\n",
        "# Function to get embedding for a single text using the OpenAI API\n",
        "def get_embedding(text, engine=ENGINE):\n",
        "    # Use the get_embeddings function to get the embedding for a single text\n",
        "    return get_embeddings([text], engine)[0]\n",
        "\n",
        "# Test the functions by getting the length of a single embedding and a list of embeddings\n",
        "len(get_embedding('hi')), len(get_embeddings(['hi', 'hello']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea70672a",
      "metadata": {
        "id": "ea70672a"
      },
      "outputs": [],
      "source": [
        "if INDEX_NAME not in pc.list_indexes().names():  # need to create the index\n",
        "    print(f'Creating index {INDEX_NAME}')\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,  # The name of the index\n",
        "        dimension=1536,  # The dimensionality of the vectors for our OpenAI embedder\n",
        "        metric='cosine',  # The similarity metric to use when searching the index\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Store the index as a variable\n",
        "index = pc.Index(name=INDEX_NAME)\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6103d6c",
      "metadata": {
        "collapsed": true,
        "id": "b6103d6c"
      },
      "outputs": [],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f2fdfe7",
      "metadata": {
        "collapsed": true,
        "id": "7f2fdfe7"
      },
      "outputs": [],
      "source": [
        "def my_hash(s):\n",
        "    # Return the MD5 hash of the input string as a hexadecimal string\n",
        "    return hashlib.md5(s.encode()).hexdigest()\n",
        "\n",
        "my_hash('I love to hash it')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd86f51",
      "metadata": {
        "id": "ecd86f51"
      },
      "outputs": [],
      "source": [
        "def prepare_for_pinecone(texts, engine=ENGINE, urls=None):\n",
        "    # Get the current UTC date and time\n",
        "    now = datetime.utcnow()\n",
        "\n",
        "    # Generate vector embeddings for each string in the input list, using the specified engine\n",
        "    embeddings = get_embeddings(texts, engine=engine)\n",
        "\n",
        "    # Create tuples of (hash, embedding, metadata) for each input string and its corresponding vector embedding\n",
        "    # The my_hash() function is used to generate a unique hash for each string, and the datetime.utcnow() function is used to generate the current UTC date and time\n",
        "    responses = [\n",
        "        (\n",
        "            my_hash(text),  # A unique ID for each string, generated using the my_hash() function\n",
        "            embedding,  # The vector embedding of the string\n",
        "            dict(text=text, date_uploaded=now)  # A dictionary of metadata, including the original text and the current UTC date and time\n",
        "        )\n",
        "        for text, embedding in zip(texts, embeddings)  # Iterate over each input string and its corresponding vector embedding\n",
        "    ]\n",
        "    if urls and len(urls) == len(texts):\n",
        "        for response, url in zip(responses, urls):\n",
        "            response[-1]['url'] = url\n",
        "\n",
        "    return responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c40d99a",
      "metadata": {
        "id": "4c40d99a"
      },
      "outputs": [],
      "source": [
        "texts = ['hi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e1b73f3",
      "metadata": {
        "collapsed": true,
        "id": "3e1b73f3"
      },
      "outputs": [],
      "source": [
        "_id, embedding, metadata = prepare_for_pinecone(texts)[0]\n",
        "\n",
        "print('ID:  ',_id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49debd5",
      "metadata": {
        "collapsed": true,
        "id": "b49debd5"
      },
      "outputs": [],
      "source": [
        "urls = ['fake.url']\n",
        "_id, embedding, metadata = prepare_for_pinecone(texts, urls=urls)[0]\n",
        "\n",
        "print('ID:  ',_id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf47aabd",
      "metadata": {
        "id": "bf47aabd"
      },
      "outputs": [],
      "source": [
        "def upload_texts_to_pinecone(texts, namespace=NAMESPACE, batch_size=None, show_progress_bar=False, urls=None):\n",
        "    # Call the prepare_for_pinecone function to prepare the input texts for indexing\n",
        "    total_upserted = 0\n",
        "    if not batch_size:\n",
        "        batch_size = len(texts)\n",
        "\n",
        "    _range = range(0, len(texts), batch_size)\n",
        "    for i in tqdm(_range) if show_progress_bar else _range:\n",
        "        text_batch = texts[i: i + batch_size]\n",
        "        if urls:\n",
        "            url_batch = urls[i: i + batch_size]\n",
        "            prepared_texts = prepare_for_pinecone(text_batch, urls=url_batch)\n",
        "        else:\n",
        "            prepared_texts = prepare_for_pinecone(text_batch)\n",
        "\n",
        "\n",
        "        # Use the upsert() method of the index object to upload the prepared texts to Pinecone\n",
        "        total_upserted += index.upsert(\n",
        "            vectors=prepared_texts,\n",
        "            namespace=namespace\n",
        "        )['upserted_count']\n",
        "\n",
        "\n",
        "    return total_upserted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b65cb2e1-f67d-4606-b0ff-c7b67aab04d8",
      "metadata": {
        "collapsed": true,
        "id": "b65cb2e1-f67d-4606-b0ff-c7b67aab04d8"
      },
      "outputs": [],
      "source": [
        "# Call the upload_texts_to_pinecone() function with the input texts\n",
        "upload_texts_to_pinecone(texts)\n",
        "\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64fa0cb-d704-42ef-b06f-5ac882a3a55a",
      "metadata": {
        "id": "f64fa0cb-d704-42ef-b06f-5ac882a3a55a"
      },
      "outputs": [],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V0XI6RAom-Ln",
      "metadata": {
        "id": "V0XI6RAom-Ln"
      },
      "outputs": [],
      "source": [
        "def query_from_pinecone(query, top_k=3, include_metadata=True):\n",
        "    # get embedding from THE SAME embedder as the documents\n",
        "    query_embedding = get_embedding(query, engine=ENGINE)\n",
        "\n",
        "    return index.query(\n",
        "      vector=query_embedding,\n",
        "      top_k=top_k,\n",
        "      namespace=NAMESPACE,\n",
        "      include_metadata=include_metadata   # gets the metadata (dates, text, etc)\n",
        "    ).get('matches')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a0871f",
      "metadata": {
        "collapsed": true,
        "id": "84a0871f"
      },
      "outputs": [],
      "source": [
        "# test that the index is empty\n",
        "query_from_pinecone('hello')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13cc8bdc",
      "metadata": {
        "id": "13cc8bdc"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "def delete_texts_from_pinecone(texts, namespace=NAMESPACE):\n",
        "    # Compute the hash (id) for each text\n",
        "    hashes = [hashlib.md5(text.encode()).hexdigest() for text in texts]\n",
        "\n",
        "    # The ids parameter is used to specify the list of IDs (hashes) to delete\n",
        "    return index.delete(ids=hashes, namespace=namespace)\n",
        "\n",
        "# delete our text\n",
        "delete_texts_from_pinecone(texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074fab6f",
      "metadata": {
        "id": "074fab6f"
      },
      "outputs": [],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c354983-ce8d-4818-98a0-e0e183909af6",
      "metadata": {
        "id": "3c354983-ce8d-4818-98a0-e0e183909af6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4523cab6-0bc3-4791-9c73-7bd7d7e5858b",
      "metadata": {
        "id": "4523cab6-0bc3-4791-9c73-7bd7d7e5858b"
      },
      "outputs": [],
      "source": [
        "base_url = 'https://developer.mozilla.org'\n",
        "mdn_web_docs_url = base_url + '/en-US/docs/Web'\n",
        "print(mdn_web_docs_url)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# get all links from mdn_web_docs_url\n",
        "urls = []\n",
        "\n",
        "# Adding headers to mimic a browser, as seen in previous attempts\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "    'Accept-Language': 'en-US,en;q=0.5',\n",
        "    'Accept-Encoding': 'gzip, deflate, br',\n",
        "    'Connection': 'keep-alive',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "    'Referer': 'https://www.google.com/'\n",
        "}\n",
        "\n",
        "r = requests.get(mdn_web_docs_url, headers=headers, timeout=10)\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "# Collect and filter relevant URLs\n",
        "filtered_urls = []\n",
        "# List of file extensions to exclude\n",
        "excluded_extensions = ['.txt', '.xml', '.json', '.rss', '.atom', '.pdf', '.zip', '.tar.gz', '.csv']\n",
        "\n",
        "for link in soup.find_all('a'):\n",
        "    if 'href' in link.attrs:\n",
        "        href = link['href']\n",
        "        full_url_candidate = None\n",
        "\n",
        "        # Handle relative URLs\n",
        "        if href.startswith('/'):\n",
        "            full_url_candidate = base_url + href\n",
        "        # Handle absolute URLs that are still within the base domain\n",
        "        elif href.startswith(base_url):\n",
        "            full_url_candidate = href\n",
        "\n",
        "        if full_url_candidate:\n",
        "            # Filter for specific documentation pages under /en-US/docs/Web/\n",
        "            # and ensure it's not the main mdn_web_docs_url itself or an anchor link.\n",
        "            # Also, exclude URLs ending with common non-HTML file extensions.\n",
        "            if full_url_candidate.startswith(base_url + '/en-US/docs/Web/') and \\\n",
        "               full_url_candidate != mdn_web_docs_url and \\\n",
        "               '#' not in full_url_candidate and \\\n",
        "               not any(full_url_candidate.endswith(ext) for ext in excluded_extensions): # Exclude non-HTML files\n",
        "                # Ensure it's a sub-page, not just the category page (by checking path segments)\n",
        "                if full_url_candidate.count('/') > mdn_web_docs_url.count('/') or \\\n",
        "                   (full_url_candidate.count('/') == mdn_web_docs_url.count('/') and full_url_candidate.endswith('/')):\n",
        "                    if full_url_candidate not in filtered_urls: # Avoid duplicates\n",
        "                        filtered_urls.append(full_url_candidate)\n",
        "urls = filtered_urls # Update the urls variable with the filtered list\n",
        "\n",
        "urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e622fbfa-2dde-4711-9c46-1390eb3430f9",
      "metadata": {
        "collapsed": true,
        "id": "e622fbfa-2dde-4711-9c46-1390eb3430f9"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "for url in tqdm(urls):\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.content, 'html.parser')\n",
        "    body = soup.find('body').get_text()\n",
        "    # CLEAN YOUR DATA HERE :)\n",
        "    texts.append(body)\n",
        "\n",
        "texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0221343a",
      "metadata": {
        "id": "0221343a"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "upload_texts_to_pinecone(texts, batch_size=BATCH_SIZE, urls=urls, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33yf7QrWtwt-",
      "metadata": {
        "id": "33yf7QrWtwt-"
      },
      "outputs": [],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gQdFZg1b0-eH",
      "metadata": {
        "id": "gQdFZg1b0-eH"
      },
      "outputs": [],
      "source": [
        " results = query_from_pinecone('I want to write HTML', top_k=3)\n",
        " for result in results:\n",
        "    print(result['metadata']['url'], result['score'], result['metadata']['text'][:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EswQgNRx0-pz",
      "metadata": {
        "id": "EswQgNRx0-pz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}